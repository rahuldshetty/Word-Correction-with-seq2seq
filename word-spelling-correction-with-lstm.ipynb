{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unigram_freq.csv']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333333, 2)\n",
      "(333333, 2)\n"
     ]
    }
   ],
   "source": [
    "# File loading\n",
    "df  = pd.read_csv('../input/unigram_freq.csv')\n",
    "print(df.shape)\n",
    "df.dropna(axis=0,how='any')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Count: 333331\n",
      "['the', 'of', 'and', 'to']\n"
     ]
    }
   ],
   "source": [
    "lines = [x for x in df['word'] if type(x) == type('a') ]\n",
    "print(\"Line Count:\",len(lines))\n",
    "print(lines[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "def process(sent):\n",
    "    sent=sent.lower()\n",
    "    sent=re.sub(r'[^0-9a-zA-Z ]','',sent)\n",
    "    sent=sent.replace('\\n','')\n",
    "    return sent    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speedkill\n",
      "biscuit\n",
      "qtt\n",
      "weathergoth\n",
      "Number of items: 333331\n"
     ]
    }
   ],
   "source": [
    "lines =[process(x) for x in lines]\n",
    "temp = []\n",
    "for line in lines:\n",
    "    temp+= [ x for x in line.split() ]\n",
    "lines = list(set(temp))\n",
    "print(\"\\n\".join(lines[:4]))\n",
    "print(\"Number of items:\",len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36}\n",
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '0', 28: '1', 29: '2', 30: '3', 31: '4', 32: '5', 33: '6', 34: '7', 35: '8', 36: '9'}\n"
     ]
    }
   ],
   "source": [
    "# CHAR INDEXING\n",
    "char_set = list(\" abcdefghijklmnopqrstuvwxyz0123456789\")\n",
    "char2int = { char_set[x]:x for x in range(len(char_set)) }\n",
    "int2char = { char2int[x]:x for x in char_set }\n",
    "print(char2int)\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '0': 27, '1': 28, '2': 29, '3': 30, '4': 31, '5': 32, '6': 33, '7': 34, '8': 35, '9': 36, '\\t': 37, '\\n': 38, '#': 39}\n",
      "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '0', 28: '1', 29: '2', 30: '3', 31: '4', 32: '5', 33: '6', 34: '7', 35: '8', 36: '9', 37: '\\t', 38: '\\n', 39: '#'}\n"
     ]
    }
   ],
   "source": [
    "count = len(char_set)\n",
    "codes = [\"\\t\",\"\\n\",'#']\n",
    "for i in range(len(codes)):\n",
    "    code = codes[i]\n",
    "    char2int[code]=count\n",
    "    int2char[count]=code\n",
    "    count+=1\n",
    "print(char2int)\n",
    "print(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: bowral\n",
      "Gibberish: bowral\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#thresh - 0 to 1\n",
    "def gen_gibberish(line,thresh=0.2):\n",
    "    times = int(random.randrange(1,len(line)) * thresh)\n",
    "    '''\n",
    "    Types of replacement:\n",
    "        1.Delete random character.\n",
    "        2.Add random character.\n",
    "        3.Replace a character.\n",
    "        4.Combination?\n",
    "    '''\n",
    "    while times!=0:\n",
    "        # try to gen noise length times...\n",
    "        times-=1\n",
    "        val = random.randrange(0,10)\n",
    "        if val <= 5:\n",
    "            #get random index\n",
    "            val = random.randrange(0,10)\n",
    "            index = random.randrange(2,len(line))\n",
    "            if val <= 3 :\n",
    "                #delete character\n",
    "                line = line[:index]+line[index+1:]\n",
    "            else:\n",
    "                #add character\n",
    "                insert_index = random.randrange(0,len(char_set))\n",
    "                line = line[:index] + char_set[insert_index] + line[index:]\n",
    "        else:\n",
    "            index = random.randrange(0,len(char_set))\n",
    "            replace_index = random.randrange(2,len(line))\n",
    "            line = line[:replace_index] + char_set[index] + line[replace_index+1:]\n",
    "    return line\n",
    "\n",
    "sample = lines[5]\n",
    "gib = gen_gibberish(sample)\n",
    "print(\"Original:\",sample)\n",
    "print(\"Gibberish:\",gib)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN OF SAMPLES: 15151\n"
     ]
    }
   ],
   "source": [
    "# create dataset\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "REPEAT_FACTOR = 1\n",
    "SKIP = int(len(lines)*0.65)\n",
    "\n",
    "for line in lines[SKIP:]:\n",
    "    if len(line)>10:\n",
    "        output_text = '\\t' + line + '\\n'\n",
    "        for _ in range(REPEAT_FACTOR):\n",
    "            input_text = gen_gibberish(line)\n",
    "            input_texts.append(input_text)\n",
    "            target_texts.append(output_text)\n",
    "print(\"LEN OF SAMPLES:\",len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Enc Len: 36\n",
      "Max Dec Len: 37\n"
     ]
    }
   ],
   "source": [
    "max_enc_len = max([len(x) for x in input_texts])\n",
    "max_dec_len = max([len(x) for x in target_texts])\n",
    "print(\"Max Enc Len:\",max_enc_len)\n",
    "print(\"Max Dec Len:\",max_dec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED ZERO VECTORS\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(input_texts)\n",
    "encoder_input_data = np.zeros( (num_samples , max_enc_len , len(char_set)),dtype='float32' )\n",
    "decoder_input_data = np.zeros( (num_samples , max_dec_len , len(char_set)+2),dtype='float32' )\n",
    "decoder_target_data = np.zeros( (num_samples , max_dec_len , len(char_set)+2),dtype='float32' )\n",
    "print(\"CREATED ZERO VECTORS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETED...\n"
     ]
    }
   ],
   "source": [
    "#filling in the enc,dec datas\n",
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[ i , t , char2int[char] ] = 1\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[ i, t , char2int[char] ] = 1\n",
    "        if t > 0 :\n",
    "            decoder_target_data[ i , t-1 , char2int[char] ] = 1\n",
    "print(\"COMPLETED...\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 1000\n",
    "latent_dim = 256\n",
    "\n",
    "num_enc_tokens = len(char_set)\n",
    "num_dec_tokens = len(char_set) + 2 # includes \\n \\t\n",
    "encoder_inputs = Input(shape=(None,num_enc_tokens))\n",
    "encoder = LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs , state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h,state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 37)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 39)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 301056      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  303104      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 39)     10023       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 614,183\n",
      "Trainable params: 614,183\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None,num_dec_tokens))\n",
    "decoder_lstm = LSTM(latent_dim,return_sequences=True,return_state=True)\n",
    "decoder_ouputs,_,_ = decoder_lstm(decoder_inputs,initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(num_dec_tokens, activation='softmax')\n",
    "decoder_ouputs = decoder_dense(decoder_ouputs)\n",
    "\n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_ouputs)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12120 samples, validate on 3031 samples\n",
      "Epoch 1/1000\n",
      "12120/12120 [==============================] - 13s 1ms/step - loss: 1.0475 - val_loss: 1.0058\n",
      "Epoch 2/1000\n",
      "12120/12120 [==============================] - 8s 696us/step - loss: 0.9644 - val_loss: 0.9287\n",
      "Epoch 3/1000\n",
      "12120/12120 [==============================] - 8s 700us/step - loss: 0.9050 - val_loss: 0.8901\n",
      "Epoch 4/1000\n",
      "12120/12120 [==============================] - 8s 687us/step - loss: 0.8718 - val_loss: 0.8626\n",
      "Epoch 5/1000\n",
      "12120/12120 [==============================] - 8s 687us/step - loss: 0.8514 - val_loss: 0.8445\n",
      "Epoch 6/1000\n",
      "12120/12120 [==============================] - 8s 689us/step - loss: 0.8368 - val_loss: 0.8310\n",
      "Epoch 7/1000\n",
      "12120/12120 [==============================] - 8s 687us/step - loss: 0.8237 - val_loss: 0.8261\n",
      "Epoch 8/1000\n",
      "12120/12120 [==============================] - 8s 691us/step - loss: 0.8116 - val_loss: 0.8164\n",
      "Epoch 9/1000\n",
      "12120/12120 [==============================] - 8s 685us/step - loss: 0.7923 - val_loss: 0.7934\n",
      "Epoch 10/1000\n",
      "12120/12120 [==============================] - 8s 687us/step - loss: 0.7731 - val_loss: 0.7713\n",
      "Epoch 11/1000\n",
      "12120/12120 [==============================] - 8s 686us/step - loss: 0.7577 - val_loss: 0.7627\n",
      "Epoch 12/1000\n",
      "12120/12120 [==============================] - 8s 691us/step - loss: 0.7433 - val_loss: 0.7502\n",
      "Epoch 13/1000\n",
      "12120/12120 [==============================] - 8s 688us/step - loss: 0.7245 - val_loss: 0.7236\n",
      "Epoch 14/1000\n",
      "12120/12120 [==============================] - 8s 683us/step - loss: 0.6972 - val_loss: 0.7006\n",
      "Epoch 15/1000\n",
      "12120/12120 [==============================] - 8s 681us/step - loss: 0.6693 - val_loss: 0.6809\n",
      "Epoch 16/1000\n",
      "12120/12120 [==============================] - 8s 681us/step - loss: 0.6507 - val_loss: 0.6557\n",
      "Epoch 17/1000\n",
      "12120/12120 [==============================] - 8s 682us/step - loss: 0.6329 - val_loss: 0.6495\n",
      "Epoch 18/1000\n",
      "12120/12120 [==============================] - 8s 686us/step - loss: 0.6134 - val_loss: 0.6329\n",
      "Epoch 19/1000\n",
      "12120/12120 [==============================] - 8s 681us/step - loss: 0.5931 - val_loss: 0.6312\n",
      "Epoch 20/1000\n",
      "12120/12120 [==============================] - 8s 686us/step - loss: 0.5756 - val_loss: 0.6037\n",
      "Epoch 21/1000\n",
      "12120/12120 [==============================] - 8s 687us/step - loss: 0.5570 - val_loss: 0.5917\n",
      "Epoch 22/1000\n",
      "12120/12120 [==============================] - 8s 689us/step - loss: 0.5396 - val_loss: 0.5793\n",
      "Epoch 23/1000\n",
      "12120/12120 [==============================] - 8s 681us/step - loss: 0.5207 - val_loss: 0.5603\n",
      "Epoch 24/1000\n",
      "12120/12120 [==============================] - 8s 677us/step - loss: 0.5016 - val_loss: 0.5421\n",
      "Epoch 25/1000\n",
      "12120/12120 [==============================] - 8s 680us/step - loss: 0.4833 - val_loss: 0.5347\n",
      "Epoch 26/1000\n",
      "12120/12120 [==============================] - 8s 682us/step - loss: 0.4663 - val_loss: 0.5133\n",
      "Epoch 27/1000\n",
      "12120/12120 [==============================] - 8s 697us/step - loss: 0.4496 - val_loss: 0.4958\n",
      "Epoch 28/1000\n",
      "12120/12120 [==============================] - 8s 677us/step - loss: 0.4349 - val_loss: 0.4935\n",
      "Epoch 29/1000\n",
      "12120/12120 [==============================] - 8s 673us/step - loss: 0.4200 - val_loss: 0.4819\n",
      "Epoch 30/1000\n",
      "12120/12120 [==============================] - 8s 670us/step - loss: 0.4054 - val_loss: 0.4806\n",
      "Epoch 31/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.3926 - val_loss: 0.4651\n",
      "Epoch 32/1000\n",
      "12120/12120 [==============================] - 9s 732us/step - loss: 0.3799 - val_loss: 0.4518\n",
      "Epoch 33/1000\n",
      "12120/12120 [==============================] - 8s 677us/step - loss: 0.3666 - val_loss: 0.4683\n",
      "Epoch 34/1000\n",
      "12120/12120 [==============================] - 8s 673us/step - loss: 0.3557 - val_loss: 0.4486\n",
      "Epoch 35/1000\n",
      "12120/12120 [==============================] - 8s 674us/step - loss: 0.3426 - val_loss: 0.4455\n",
      "Epoch 36/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.3344 - val_loss: 0.4392\n",
      "Epoch 37/1000\n",
      "12120/12120 [==============================] - 8s 685us/step - loss: 0.3224 - val_loss: 0.4343\n",
      "Epoch 38/1000\n",
      "12120/12120 [==============================] - 8s 669us/step - loss: 0.3115 - val_loss: 0.4368\n",
      "Epoch 39/1000\n",
      "12120/12120 [==============================] - 8s 671us/step - loss: 0.3018 - val_loss: 0.4264\n",
      "Epoch 40/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.2914 - val_loss: 0.4287\n",
      "Epoch 41/1000\n",
      "12120/12120 [==============================] - 8s 678us/step - loss: 0.2819 - val_loss: 0.4195\n",
      "Epoch 42/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.2727 - val_loss: 0.4253\n",
      "Epoch 43/1000\n",
      "12120/12120 [==============================] - 8s 674us/step - loss: 0.2637 - val_loss: 0.4204\n",
      "Epoch 44/1000\n",
      "12120/12120 [==============================] - 8s 672us/step - loss: 0.2547 - val_loss: 0.4157\n",
      "Epoch 45/1000\n",
      "12120/12120 [==============================] - 8s 674us/step - loss: 0.2468 - val_loss: 0.4310\n",
      "Epoch 46/1000\n",
      "12120/12120 [==============================] - 8s 672us/step - loss: 0.2381 - val_loss: 0.4047\n",
      "Epoch 47/1000\n",
      "12120/12120 [==============================] - 8s 676us/step - loss: 0.2297 - val_loss: 0.4149\n",
      "Epoch 48/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.2210 - val_loss: 0.4173\n",
      "Epoch 49/1000\n",
      "12120/12120 [==============================] - 8s 681us/step - loss: 0.2140 - val_loss: 0.4159\n",
      "Epoch 50/1000\n",
      "12120/12120 [==============================] - 8s 670us/step - loss: 0.2061 - val_loss: 0.4173\n",
      "Epoch 51/1000\n",
      "12120/12120 [==============================] - 8s 683us/step - loss: 0.1989 - val_loss: 0.4138\n",
      "Epoch 52/1000\n",
      "12120/12120 [==============================] - 8s 674us/step - loss: 0.1914 - val_loss: 0.4202\n",
      "Epoch 53/1000\n",
      "12120/12120 [==============================] - 8s 668us/step - loss: 0.1846 - val_loss: 0.4199\n",
      "Epoch 54/1000\n",
      "12120/12120 [==============================] - 8s 672us/step - loss: 0.1784 - val_loss: 0.4215\n",
      "Epoch 55/1000\n",
      "12120/12120 [==============================] - 8s 672us/step - loss: 0.1709 - val_loss: 0.4261\n",
      "Epoch 56/1000\n",
      "12120/12120 [==============================] - 8s 670us/step - loss: 0.1652 - val_loss: 0.4331\n",
      "Epoch 57/1000\n",
      "12120/12120 [==============================] - 8s 675us/step - loss: 0.1593 - val_loss: 0.4419\n",
      "Epoch 58/1000\n",
      "12120/12120 [==============================] - 8s 678us/step - loss: 0.1525 - val_loss: 0.4303\n",
      "Epoch 59/1000\n",
      "12120/12120 [==============================] - 8s 670us/step - loss: 0.1469 - val_loss: 0.4368\n",
      "Epoch 60/1000\n",
      "12120/12120 [==============================] - 8s 670us/step - loss: 0.1410 - val_loss: 0.4357\n",
      "Epoch 61/1000\n",
      "12120/12120 [==============================] - 8s 678us/step - loss: 0.1357 - val_loss: 0.4412\n",
      "Epoch 62/1000\n",
      "12120/12120 [==============================] - 8s 678us/step - loss: 0.1303 - val_loss: 0.4428\n",
      "Epoch 63/1000\n",
      " 5888/12120 [=============>................] - ETA: 3s - loss: 0.1232"
     ]
    }
   ],
   "source": [
    "h=model.fit([encoder_input_data,decoder_input_data],decoder_target_data\n",
    "         ,epochs = epochs,\n",
    "          batch_size = batch_size,\n",
    "          validation_split = 0.2\n",
    "         )\n",
    "model.save('s2s.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'input_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Wrong sentence: subramaniam\n",
      "Corrected sentence: subramaniam\n",
      "\n",
      "Ground Truth: \tsubramaniam\n",
      "\n",
      "-\n",
      "Wrong sentence: supplement0ng\n",
      "Corrected sentence: supplementing\n",
      "\n",
      "Ground Truth: \tsupplementing\n",
      "\n",
      "-\n",
      "Wrong sentence: unquestioing\n",
      "Corrected sentence: unquestioning\n",
      "\n",
      "Ground Truth: \tunquestioning\n",
      "\n",
      "-\n",
      "Wrong sentence: se7sialportal\n",
      "Corrected sentence: serialportal\n",
      "\n",
      "Ground Truth: \tserialportal\n",
      "\n",
      "-\n",
      "Wrong sentence: accentuated\n",
      "Corrected sentence: accentuated\n",
      "\n",
      "Ground Truth: \taccentuated\n",
      "\n",
      "-\n",
      "Wrong sentence: negativland\n",
      "Corrected sentence: negativland\n",
      "\n",
      "Ground Truth: \tnegativland\n",
      "\n",
      "-\n",
      "Wrong sentence: tawneestone\n",
      "Corrected sentence: tawneestone\n",
      "\n",
      "Ground Truth: \ttawneestone\n",
      "\n",
      "-\n",
      "Wrong sentence: soundtracks\n",
      "Corrected sentence: soundtracks\n",
      "\n",
      "Ground Truth: \tsoundtracks\n",
      "\n",
      "-\n",
      "Wrong sentence: uninstallation\n",
      "Corrected sentence: uninstaltability\n",
      "\n",
      "Ground Truth: \tuninstallation\n",
      "\n",
      "-\n",
      "Wrong sentence: beasfiality\n",
      "Corrected sentence: beasfiality\n",
      "\n",
      "Ground Truth: \tbeasfiality\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs,encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
    "decoder_outputs,state_h,state_c = decoder_lstm(\n",
    "        decoder_inputs,initial_state = decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h,state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "encoder_model.save('encoder.h5')\n",
    "decoder_model.save('decoder.h5')\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_dec_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, char2int['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = int2char[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_dec_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_dec_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "for seq_index in range(10):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Wrong sentence:', input_texts[seq_index])\n",
    "    print('Corrected sentence:', decoded_sentence)\n",
    "    print('Ground Truth:',target_texts[seq_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
